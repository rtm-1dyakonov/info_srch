# Инфопоиск (1, 2, 4, 5)
## Раздьяконов Артём, группа S41012. 
Выполненные задания: 1, 2, 4, 5

1)  Для подготовки данных я использовал скрапер wiki-страниц. Было выбрано N непересекающихся тем:
  * игроки и тренеры лиги NHL
  * метрополитен в городах Азии
  * породы спортивных скаковых лошадей
  * индонезийские телесериалы
  * игроки лиги CFL
  * игроки лиги MLB
  * оперные исполнители и оперные песни (преимущественно итальянские)
  * провинции Италии
2) Для использования подхода tf-idf был применён TfidfVectorizer из sklearn.feature_extraction.text.
3) Оценка качества производится по метрикам precision, recall, f1 и mrr.
4) Для обработки изображений, которые сохранятся после выполнения кода в папке images внутри директории cv_part, используется модель Xception с приведением изображений к размерам 299 на 299.


## Запуск проекта
1. Установка всего необходимого (nltk, bs4, keras, translate)

```pip install -e .```

2. Иногда с пакетом stopwords возникают проблемы, так что на всякий случай лучше прописать следующее

```python -m nltk.downloader stopwords```

3. Создать пустую папку images внутри директории cv_part

4. Создание модели на основе алгоритма tf-idf по собраным html-странциам, который лежат в папке html

```tfidf "<абсолютный/путь/до/папки/html/>```

5. Для того, чтобы получить 2 самых близких/релевантных по косинусному расстоянию страницы по введённому запросу, нужно ввести следующее

```request "<запрос>"```

6. Для вычисления метрик по запросам из файла разметки прописать

```quality "<абсолютный/путь/до/файла/markup.csv>"```
